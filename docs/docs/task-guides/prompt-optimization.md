---
sidebar_position: 3
title: Prompt Optimization
---


#### Overview
Design and improve prompt workflows for LLMs using a drag-and-drop builder.

#### Constructing & Optimizing LLM Flows
- Use the no-code builder to connect steps (inputs, prompts, evaluations).
- Visualize and refine your flow logic.

#### Setting Up Model Providers
1. Go to **Settings > Model Providers**.
2. Connect your OpenAI or Anthropic key.
3. Select the provider in your optimization task.

#### Optimization Configurations
Customize prompt versions, temperature, max tokens, and evaluation criteria.

#### Running Optimizations
1. Define prompt candidates.
2. Run evaluations.
3. View metrics and pick the best configuration.
